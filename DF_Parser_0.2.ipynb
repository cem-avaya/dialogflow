{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6cb0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON data\n",
    "\n",
    "json_file_path = r'C:\\Users\\mueller15\\OneDrive - Avaya\\AXP Analytics\\DialogFlow\\bquxjob_1badbb0_187b38bd236.json'\n",
    "\n",
    "with open(json_file_path, 'r') as j:\n",
    "    data = json.loads(j.read())\n",
    "\n",
    "\n",
    "# Create an empty list to hold the parsed data\n",
    "parsed_data = []\n",
    "\n",
    "# Loop through each conversation turn and extract the relevant information\n",
    "for turn in data:\n",
    "    conversation_name = turn['conversation_name'].split(\"/\").pop()\n",
    "    turn_position = turn['turn_position']\n",
    "    request_time = turn['request_time'].split(\" UTC\")[0]\n",
    "    language_code = turn['language_code']\n",
    "    request = json.loads(turn['request'])\n",
    "    response = json.loads(turn['response'])\n",
    "    derived_data = json.loads(turn['derived_data'])\n",
    "    conversation_signals = json.loads(turn['conversation_signals'])\n",
    "\n",
    "    # Create a dictionary with the parsed data for this conversation turn\n",
    "    parsed_turn = {\n",
    "        'conversation_name': conversation_name,\n",
    "        'turn_position': turn_position,\n",
    "        'request_time': request_time,\n",
    "        'language_code': language_code,\n",
    "        'request': request,\n",
    "        'response': response,\n",
    "        'derived_data': derived_data,\n",
    "        'conversation_signals': conversation_signals\n",
    "    }\n",
    "\n",
    "    # Append the parsed data for this conversation turn to the list of parsed data\n",
    "    parsed_data.append(parsed_turn)\n",
    "\n",
    "# Create a pandas DataFrame from the parsed data, with a unique identifier column\n",
    "df = pd.DataFrame(parsed_data)\n",
    "df['unique_identifier'] = df['conversation_name'] + '_' + df['turn_position']\n",
    "\n",
    "def flatten_json_columns(df):\n",
    "    \"\"\"\n",
    "    Flatten all columns that contain JSON data into new columns.\n",
    "    \"\"\"\n",
    "    json_columns = []\n",
    "    for column in df.columns:\n",
    "        if df[column].apply(lambda x: isinstance(x, (dict, list))).all():\n",
    "            json_columns.append(column)\n",
    "\n",
    "    for column in json_columns:\n",
    "        column_data = df[column].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "        flattened_data = pd.json_normalize(column_data)\n",
    "        flattened_data.columns = [f\"{column}_{col}\" for col in flattened_data.columns]\n",
    "        df = pd.concat([df, flattened_data], axis=1)\n",
    "        df = df.drop(column, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def compute_latency(latency_list):\n",
    "    latency = latency_list[0].get('nanos')/1000000000 + float(latency_list[0].get('seconds') or 0)\n",
    "    return latency\n",
    "        \n",
    "    \n",
    "df = flatten_json_columns(df)\n",
    "df['response_queryResult.webhookLatencies'] = df['response_queryResult.webhookLatencies'].map(lambda x: compute_latency(x) if type(x) == list else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\mueller15\\OneDrive - Avaya\\AXP Analytics\\DialogFlow\\bquxjob_1badbb0_187b38bd236.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
